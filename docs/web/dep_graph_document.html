

<!DOCTYPE html>
<html>
<head>
  <title>Dependency graph</title>
  <meta name="generator" content="plasTeX" />
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="styles/theme-white.css" />
  <link rel="stylesheet" href="styles/dep_graph.css" />
  
  <script type="text/x-mathjax-config">
  
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  
  </script>

  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">  </script>


<link rel="stylesheet" href="styles/extra_styles.css" />

</head>

<body>

\(
\renewcommand\ref{\text}
\)

<header>
  <a class="toc" href="index.html">Home</a>
  <h1 id="doc_title">Dependencies</h1>
</header>
<div class="wrapper">
<div class="content">
    <div id="graph"></div>
<div id="statements">

    
    <div class="dep-modal-container" id="lem:ApxSolveLoad_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:ApxSolveLoad" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#lem:ApxSolveLoad">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">3.10</span></div>
    </a>
    <div class="thm_thmcontent"><p> For any approximation factor \(0 {\lt} \epsilon {\lt} 1\), and any weighted graph \((G,w)\), let \(\textrm{load}_w= \left( w_e \sum _f |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}|\right)_{e \in E} \) be the true loads, and \(\textrm{aload}_w= \text{GetApproxLoad}(G, w, \epsilon )\) be the approximate loads computed by the algorithm when using an approximate Laplacian solver. Then with probability \(\ge 1-\frac{1}{poly(n)}\), </p>
<div class="displaymath" id="a0000000035">
  \[  (1 - \epsilon ) \cdot \textrm{load}_w(e) \le \textrm{aload}_w(e) \le (1 + \epsilon ) \cdot \textrm{load}_w(e) \qquad \text{for all $e \in E$}  \]
</div>
</div>

  <div class="proof_wrapper" id="a0000000034">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>Let \(U = L^{\dagger }B^{\mkern -1.5mu\mathsf{T}}C^{\mkern -1.5mu\mathsf{T}}\), and \(\widetilde{U}= \text{ApproxLapSolve}(L, B^{\mkern -1.5mu\mathsf{T}}C^{\mkern -1.5mu\mathsf{T}}, \delta , \epsilon _L)\) where we abuse notation to mean that \(\text{ApproxLapSolve}\) runs on each column of \(B^{\mkern -1.5mu\mathsf{T}}C^{\mkern -1.5mu\mathsf{T}}\) and returns a column vector. Let \(R_i\) and \(\widetilde{R}_i\) denote the rows, and \(C_j\) and \(\widetilde{C}_j\) denote the columns of \(U\) and \(\widetilde{U}\) respectively. By guarantees of the approximate Laplacian solver, we have </p>
<div class="displaymath" id="a0000000036">
  \[  \| \widetilde{C}_j - C_j\| _L \le \epsilon _L\| C_j\| _L  \]
</div>
<p> Lemma <a href="sec-apxlsolve.html#lem:InftyClose">3.6</a> tells us that </p>
<div class="displaymath" id="a0000000037">
  \[  \| \widetilde{C}_j - C_j\| _{\infty } \le \epsilon _L\cdot 2n^3\cdot \| C_j\| _{\infty }  \]
</div>
<p> With \(K\) as an upper bound on the maximum entry in \(CBL^{\dagger }\), and using the above inequality in Lemma <a href="sec-apxlsolve.html#lem:RowtoColumnInfty">3.7</a>, we get that </p>
<div class="displaymath" id="a0000000038">
  \[  \| \widetilde{R}_i - R_i\| _{\infty } \le \epsilon _L\cdot 2n^3\cdot K \]
</div>
<p> Note that for any \(e = (u, v)\), \((U^{\mkern -1.5mu\mathsf{T}}b_e)^{\mkern -1.5mu\mathsf{T}}= R_u - R_v\), and \((\widetilde{U}^{\mkern -1.5mu\mathsf{T}}b_e)^{\mkern -1.5mu\mathsf{T}}= \widetilde{R}_u - \widetilde{R}_v\). Thus </p>
<div class="displaymath" id="a0000000039">
  \begin{align*}  \| (U^{\mkern -1.5mu\mathsf{T}}b_e) - (\widetilde{U}^{\mkern -1.5mu\mathsf{T}}b_e)\| _{\infty } & = \| (R_u - R_v) - (\widetilde{R}_u - \widetilde{R}_v)\| _{\infty } \\ & \le \| R_u - \widetilde{R}_u\| _{\infty } + \| R_v - \widetilde{R}_v\| _{\infty } \\ & \le 4\epsilon n^3 K\end{align*}
</div>
<p> By choice of \(\epsilon _L= \frac{\epsilon }{( 8m n^4 K)}\), the final expression is \(\frac{\epsilon }{2 mn}\). Since \(\text{RecoverNorm}(x_1, x_2, \ldots , x_\ell ) = \text{median}(|x_1|, |x_2|, \ldots , |x_\ell |)\), and since the guarantees of \(\text{RecoverNorm}\) from Theorem <a href="sec-apxlsolve.html#thm:SketchApprox">3.2</a> gives us </p>
<div class="displaymath" id="a0000000040">
  \[  \left(1-\frac{\epsilon }{2}\right)\cdot \sum _f |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}|\le \text{RecoverNorm}(U^{\mkern -1.5mu\mathsf{T}}b_e) \le \left(1+\frac{\epsilon }{2}\right)\cdot \sum _f |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}|,  \]
</div>
<p> using Lemma <a href="sec-apxlsolve.html#lem:CombinedApx">3.9</a> on \(U^{\mkern -1.5mu\mathsf{T}}b_e\) and \(\widetilde{U}^{\mkern -1.5mu\mathsf{T}}b_e\), we get </p>
<div class="displaymath" id="a0000000041">
  \[  \left(1-\frac{\epsilon }{2}\right)\cdot \sum _f |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}|- \frac{\epsilon }{2 mn}\le \text{RecoverNorm}(\widetilde{U}^{\mkern -1.5mu\mathsf{T}}b_e) \le \left(1+\frac{\epsilon }{2}\right)\cdot \sum _f |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}|+ \frac{\epsilon }{2 mn}.  \]
</div>
<p> Thus, </p>
<div class="displaymath" id="a0000000042">
  \[  \left(1-\frac{\epsilon }{2}\right)\cdot \textrm{load}_w(e) - \frac{\epsilon w_e}{2mn} \le \text{GetApproxLoad}(G, w) \le \left(1+\frac{\epsilon }{2}\right)\cdot \textrm{load}_w(e) + \frac{\epsilon w_e}{2mn}  \]
</div>
<p> Since for any edge \(f \in E,\) we have \(w_f = \left( p_f + \frac{1}{m} \right)^{-1} \le m\), we get \(w_{\max } \le m.\) Thus, Lemma <a href="sec-apxlsolve.html#lem:LoadLB">3.3</a> gives us that \(\textrm{load}_w(e) \ge \frac{w_e}{mn},\) which proves our lemma. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:CombinedApx_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:CombinedApx" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#lem:CombinedApx">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">3.9</span></div>
    </a>
    <div class="thm_thmcontent"><p> Let \(a \in \mathbb {R}\) be a real number. Suppose \(x \in \mathbb {R}^\ell \) satisfies </p>
<div class="displaymath" id="a0000000031">
  \[  (1-\epsilon )\cdot a \le \text{median}(|x_1|, |x_2|, \ldots , |x_\ell |)\le (1+\epsilon )\cdot a  \]
</div>
<p> Suppose \(y \in \mathbb {R}^\ell \) is such that \(\| x - y\| _{\infty } \le \epsilon ’\), then \(y\) satisfies </p>
<div class="displaymath" id="a0000000032">
  \[  (1-\epsilon )\cdot a - \epsilon ’\le \text{median}(|y_1|, |y_2|, \ldots , |y_\ell |)\le (1+\epsilon )\cdot a + \epsilon ’ \]
</div>
</div>

  <div class="proof_wrapper" id="a0000000030">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>Using Lemma <a href="sec-apxlsolve.html#lem:MedianApx">3.8</a> and the assumption on \(x\), </p>
<div class="displaymath" id="a0000000033">
  \begin{align*}  (1-\epsilon )\cdot a - \epsilon ’& \le \text{median}(|x_1|, |x_2|, \ldots , |x_\ell |)- \epsilon ’\\ & \le \text{median}(|y_1|, |y_2|, \ldots , |y_\ell |)\\ & \le \text{median}(|x_1|, |x_2|, \ldots , |x_\ell |)+ \epsilon ’\\ & \le (1+\epsilon )\cdot a + \epsilon ’\end{align*}
</div>
<p> as required. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:InftyClose_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:InftyClose" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#lem:InftyClose">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">3.6</span></div>
    </a>
    <div class="thm_thmcontent"><p> Suppose we have two vectors \(x, y \in \mathbb {R}^n\) such that \(x, y \perp 1\) and \(\| x - y\| _L \le \epsilon \| y\| _L\). Then \(\| x - y\| _{\infty } \le \epsilon \cdot 2n^3\cdot \| y\| _{\infty }\). </p>
</div>

  <div class="proof_wrapper" id="a0000000022">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>By Lemmas <a href="sec-apxlsolve.html#lem:InftyLUB">3.5</a> and <a href="sec-apxlsolve.html#lem:InftyLLB">3.4</a>, we have </p>
<div class="displaymath" id="a0000000023">
  \[  n^{-2}\cdot \| x-y\| _{\infty } \le \| x-y\| _L \qquad \text{and}\qquad \| y\| _L \le 2n\cdot \| y\| _{\infty }  \]
</div>
<p> Together with the assumption in our lemma, we get </p>
<div class="displaymath" id="a0000000024">
  \[  \| x - y\| _{\infty } \le n^{2}\cdot \| x - y\| _L \le \epsilon \cdot n^{2}\cdot \| y\| _L \le \epsilon \cdot 2n^3\cdot \| y\| _{\infty }  \]
</div>
<p> as claimed. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:InftyLLB_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:InftyLLB" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#lem:InftyLLB">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">3.4</span></div>
    </a>
    <div class="thm_thmcontent"><p> For any \(x \in \mathbb {R}^n\) such that \(x \perp 1\), we have \(n^{-2}\cdot \| x\| _{\infty } \le \| x\| _L\). </p>
</div>

  <div class="proof_wrapper" id="a0000000017">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>Since \(\min _{x \in \mathbb {R}^n} \| x\| _L^2 / \| x\| _2^2 = 0\) which is attained by \(1\), by the variational characterization of eigenvalues of a symmetric matrix, the second smallest eigenvalue \(\lambda _2\) of \(L\) is given by </p>
<div class="displaymath" id="a0000000018">
  \[  \min _{x \in \mathbb {R}^n: x \perp 1} \frac{\| x\| _L^2}{\| x\| _2^2} = \lambda _2  \]
</div>
<p> By Cheeger’s inequality, \(\lambda _2 \ge h^2/2\Delta \), where \(h = \min _{S : |S| \le n/2} |E(S, \overline{S})|/|S|\) is the unnormalized Cheeger’s constant and \(\Delta \) is the maximum degree in the graph. Thus </p>
<div class="displaymath" id="a0000000019">
  \[  \lambda _2 \ge h^2 \cdot \frac{1}{2\Delta } \ge \frac{4}{n^2} \cdot \frac{1}{2n} \ge n^{-3}  \]
</div>
<p> Thus for any \(x \in \mathbb {R}^n\) such that \(x \perp 1\), \(\| x\| _L \ge n^{-3/2} \cdot \| x\| _2 \ge n^{-3/2} \cdot \| x\| _{\infty }\), and the lemma follows. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:InftyLUB_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:InftyLUB" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#lem:InftyLUB">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">3.5</span></div>
    </a>
    <div class="thm_thmcontent"><p> For any \(x \in \mathbb {R}^n\), \(\| x\| _L \le 2n\cdot \| x\| _{\infty }\). </p>
</div>

  <div class="proof_wrapper" id="a0000000020">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>Since \(\| x\| _{\infty }^2 \le 1\) implies \(|x_i|\le 1\) for all \(i \in [n]\), and since \(\| x\| _L^2 = x^{\mkern -1.5mu\mathsf{T}}L x\), we have </p>
<div class="displaymath" id="a0000000021">
  \begin{equation*}  \max _{x \in \mathbb {R}^n} \frac{\| x\| _L^2}{\| x\| _{\infty }^2} \le \max _{x \in \mathbb {R}^n: |x_i| \le 1} x^{\mkern -1.5mu\mathsf{T}}L x \end{equation*}
</div>
<p> Since \(x^{\mkern -1.5mu\mathsf{T}}L x = \sum _{(u,v) \in E} (x_u - x_v)^2\), and \(|x_i| \le 1,\) each term is bounded by 4. Thus, the sum is at most \(4m \le 4n^{2},\) giving the lemma. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:LoadLB_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:LoadLB" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#lem:LoadLB">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">3.3</span></div>
    </a>
    <div class="thm_thmcontent"><p> For any weighted graph \((G, w)\), the load on any edge \(e\) has the following lower bound. </p>
<div class="displaymath" id="a0000000016">
  \[  \textrm{load}_w(e) \ge \frac{2w_{e}}{nw_{\max }},  \]
</div>
<p> where \(w_{\max }\) is the maximum edge weight. </p>
</div>

  </div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:Localization_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:Localization" style="display: none">
    <a class="latex_link" target="_blank" href="sec-proofOracleReturn.html#lem:Localization">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">1.1</span></div>
    </a>
    <div class="thm_thmcontent"><p> Let \(G\) be a graph with weights \(\{ w_e\} \). Then for any vector \(\ell \in \mathbb {R}_{\ge 0}^m\), </p>
<div class="displaymath" id="a0000000002">
  \[  \sum _{e, f \in E} \ell _e \ell _f \sqrt{w_e w_f} |b_e L_G^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}| \le \alpha _{\text{local}}\cdot \| \ell \| _2^2  \]
</div>
</div>

  </div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:MedianApx_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:MedianApx" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#lem:MedianApx">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">3.8</span></div>
    </a>
    <div class="thm_thmcontent"><p> Let \(x, y \in \mathbb {R}^\ell \) be such that \(\| x - y\| _{\infty } \le \epsilon \), where \(\ell \) is odd. Then </p>
<div class="displaymath" id="a0000000029">
  \[  \text{median}(|x_1|, |x_2|, \ldots , |x_\ell |)- \epsilon \le \text{median}(|y_1|, |y_2|, \ldots , |y_\ell |)\le \text{median}(|x_1|, |x_2|, \ldots , |x_\ell |)+ \epsilon  \]
</div>
</div>

  <div class="proof_wrapper" id="a0000000028">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>Note that if \(|x_i - y_i| \le \epsilon \), then \(| |x_i| - |y_i| | \le \epsilon \) as well. Thus we can assume without loss of generality that \(x\) and \(y\) are non-negative. </p>
<p>Relabel the indices such that \(x_1 \le x_2 \le \ldots \le x_\ell \) are in non-decreasing order. The assumption on \(\ell _{\infty }\) norm gives us that for all \(i \in [\ell ]\), </p>
<div class="equation" id="eq:MedianApx">
<p>
  <div class="equation_content">
    \begin{equation}  \label{eq:MedianApx} |x_i - y_i| \le \epsilon \end{equation}
  </div>
  <span class="equation_label">1</span>
</p>
</div>
<p> Let \(\pi \) be a permutation such that \(y_{\pi (1)} \le y_{\pi (2)} \le \ldots \le y_{\pi (\ell )}\) is in non-decreasing order. Let \(m= \left\lceil \ell /2 \right\rceil \). We want to show that \(|y_{\pi (m)} - x_{m}| \le \epsilon \). If \(m= \pi (m)\), then the lemma follows from Equation <a href="sec-apxlsolve.html#eq:MedianApx">1</a> with \(i = m\). So assume that \(m\neq \pi (m)\). </p>
<p>Consider the case when \(m{\gt} \pi (m)\). Then since \(y_{m} \ge y_{\pi (m)}\), we have \(x_{m} \ge y_{m} - \epsilon \ge y_{\pi (m)} - \epsilon \). For the other direction, since \(m{\gt} \pi (m)\), there exists an index \(j\) such that \(x_j {\gt} x_{m}\) and \(y_j \le y_{\pi (m)}\). For this index, we have \(y_{\pi (m)} \ge y_j \ge x_j - \epsilon \ge x_m - \epsilon \) as required. The case when \(m{\lt} \pi (m)\) is symmetric. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:OracleReturn_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:OracleReturn" style="display: none">
    <a class="latex_link" target="_blank" href="sec-proofOracleReturn.html#lem:OracleReturn">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">1.2</span></div>
    </a>
    <div class="thm_thmcontent"><p> For any probability distribution \(p \in \Delta ^m\), the oblivious routing \(M_w\) corresponding to the electrical network with weights \(w_e = \left( p_e + \frac{1}{m} \right)^{-1}\) satisfies \(\sum _e p_e \textrm{load}_w(e) \le 2\alpha _{\text{local}}\). </p>
</div>

  <div class="proof_wrapper" id="a0000000003">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>Setting \(\ell _e\) to \(\frac{1}{\sqrt{w_e}}\) and applying Lemma&#160;<a href="sec-proofOracleReturn.html#lem:Localization">1.1</a>, we get </p>
<div class="displaymath" id="a0000000004">
  \begin{align*}  \sum _e p_e \textrm{load}_w(e) & = \sum _e p_e \sum _{f} \textrm{load}_w(f\to e) \\ & = \sum _e p_e \cdot w_e \cdot \sum _{f} |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}| \tag *{(by definition of load)}\\ & = \sum _e p_e \cdot \left( p_e + \frac{1}{m} \right)^{-1}\cdot \sum _{f} |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}| \tag *{(by definition of $w_e$)}\\ & \le \sum _e \sum _{f} |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}| \\ & = \sum _{e, f} \frac{1}{\sqrt{w_e w_f}} \cdot \sqrt{w_ew_f} \cdot |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}| \\ & = \sum _{e, f} \ell _e \ell _f \cdot \sqrt{w_e w_f} \cdot |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}| \tag *{(by choice of $\ell _e$)}\\ & \le \alpha _{\text{local}}\cdot \| \ell \| _2^2 \tag *{(by Lemma \ref{lem:Localization})} \\ & = \alpha _{\text{local}}\cdot \sum _e \frac{1}{w_e} \\ & = \alpha _{\text{local}}\cdot \sum _e \left( p_e + \frac{1}{m} \right) \\ & = 2 \alpha _{\text{local}}, \end{align*}
</div>
<p> as required. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:Pi_is_Projection_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:Pi_is_Projection" style="display: none">
    <a class="latex_link" target="_blank" href="sec-proofWidthBound.html#lem:Pi_is_Projection">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">2.1</span></div>
    </a>
    <div class="thm_thmcontent"><p> The matrix \(\Pi \) is a projection matrix. </p>
</div>

  <div class="proof_wrapper" id="a0000000005">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>We show that \(\Pi ^2 = \Pi \). </p>
<div class="displaymath" id="a0000000006">
  \begin{align*}  \Pi ^2 & = \left( W^{\frac{1}{2}} B L^{\dagger }B^{\mkern -1.5mu\mathsf{T}}W^{\frac{1}{2}} \right) \cdot \left( W^{\frac{1}{2}} B L^{\dagger }B^{\mkern -1.5mu\mathsf{T}}W^{\frac{1}{2}} \right) \\ & = \left( W^{\frac{1}{2}} B \right) \cdot \left( L^{\dagger }B^{\mkern -1.5mu\mathsf{T}}W B L^{\dagger }\right) \cdot \left( B^{\mkern -1.5mu\mathsf{T}}W^{\frac{1}{2}} \right) \\ & = \left( W^{\frac{1}{2}} B \right) \cdot L^{\dagger }\cdot \left( B^{\mkern -1.5mu\mathsf{T}}W^{\frac{1}{2}} \right)= \Pi . \end{align*}
</div>
<p> as required. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:RowtoColumnInfty_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:RowtoColumnInfty" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#lem:RowtoColumnInfty">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">3.7</span></div>
    </a>
    <div class="thm_thmcontent"><p> Let \(U\) be an \(n \times \ell \) matrix, with \(K\) being the largest value present in the matrix. Let \(\widetilde{U}\) be an approximation of \(U\) such that for every \(j \in [\ell ]\), the \(j\)-th column \(\widetilde{C}_j\) of \(\widetilde{U}\) is \(\epsilon \)-close to the \(j\)-th column \(C_j\) of \(U\) in the following sense: \(\forall j \in [\ell ], \| \widetilde{C}_j - C_j\| _{\infty } \le \epsilon \cdot \| C_j\| _{\infty }\). Then for any \(i \in [n]\), and rows \(R_i\) of \(U\) and \(\widetilde{R}_i\) of \(\widetilde{U}\), </p>
<div class="displaymath" id="a0000000026">
  \[  \|  \widetilde{R}_i - R_i \| _{\infty } \le \epsilon \cdot K \]
</div>
</div>

  <div class="proof_wrapper" id="a0000000025">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>For any \(i \in [n]\), </p>
<div class="displaymath" id="a0000000027">
  \begin{align*}  \| \widetilde{R}_i - R_i\| _{\infty } & \le \max _{i \in [n]} \| \widetilde{R}_i - R_i\| _{\infty } \\ & = \max _{i, j \in [n] \times [\ell ]} | \widetilde{U}_{ij} - U_{ij} | \\ & = \max _{j\in [\ell ]} \|  \widetilde{C}_{j} - C_{j} \| _{\infty } \\ & \le \epsilon \cdot \max _{j \in [\ell ]} \|  C_{j} \| _{\infty } \\ & \le \epsilon \cdot K\end{align*}
</div>
<p> as required. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:WidthBound_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:WidthBound" style="display: none">
    <a class="latex_link" target="_blank" href="sec-proofWidthBound.html#lem:WidthBound">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">2.3</span></div>
    </a>
    <div class="thm_thmcontent"><p> For any probability distribution \(p \in \Delta ^m\), the oblivious routing \(M_w\) corresponding to the electrical network with weights \(w_e = \left( p_e + \frac{1}{m} \right)^{-1}\) satisfies \(\textrm{load}_w(e) \le \sqrt{2m}\) for every edge \(e\). </p>
</div>

  <div class="proof_wrapper" id="a0000000010">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>Fixing an edge \(e\), </p>
<div class="displaymath" id="a0000000011">
  \begin{align*}  \textrm{load}_w(e) & = w_e \sum _f |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}| \\ & \le \sum _f \sqrt{\frac{w_e}{w_f}} \cdot \sqrt{w_e w_f} |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}| \\ & \le \sqrt{\sum _f \frac{w_e}{w_f}} \cdot \sqrt{\sum _f w_e w_f |b_e L^{\dagger }b_f^{\mkern -1.5mu\mathsf{T}}|^2} \tag *{(by Cauchy-Schwarz)} \end{align*}
</div>
<p>We now bound each of the two terms separately. For the first term, note that </p>
<div class="displaymath" id="a0000000012">
  \begin{align*}  w_e \cdot \sum _f \frac{1}{w_f} & = \left( p_e + \frac{1}{m} \right)^{-1}\cdot \sum _f \left( p_f + \frac{1}{m}\right) \\ & \le 2 \cdot \left( p_e + \frac{1}{m} \right)^{-1}\\ & \le 2 \cdot \frac{1}{\left(\frac{1}{m}\right)} = 2m. \end{align*}
</div>
<p>For the second term, by Lemma&#160;<a href="sec-proofWidthBound.html#lem:widthHelpfulLemma">2.2</a>, we know that </p>
<div class="displaymath" id="a0000000013">
  \[  \sum _f w_e w_f |b_e L^{\dagger }b_f ^{\mkern -1.5mu\mathsf{T}}|^2 \leq 1.  \]
</div>
<p>Putting these two inequalities together, we get that \(\textrm{load}_w(e) \le \sqrt{2m}\) for any edge \(e\), which gives the desired bound of \(\sqrt{2m}\) on the width. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:widthHelpfulLemma_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:widthHelpfulLemma" style="display: none">
    <a class="latex_link" target="_blank" href="sec-proofWidthBound.html#lem:widthHelpfulLemma">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">2.2</span></div>
    </a>
    <div class="thm_thmcontent"><p> Let \(G\) be a graph with weights \(\{ w_e\} \) and let \(L\) be the Laplacian matrix associated with \(G\). For any edge \(e\), we have that </p>
<div class="displaymath" id="a0000000008">
  \[  \sum _f w_e w_f |b_e L^{\dagger }b_f ^{\mkern -1.5mu\mathsf{T}}|^2 \leq 1.  \]
</div>
</div>

  <div class="proof_wrapper" id="a0000000007">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>By Lemma&#160;<a href="sec-proofWidthBound.html#lem:Pi_is_Projection">2.1</a> we know that \(\Pi \) is a projection matrix. This in particular implies that the diagonal entries of \(\Pi \) (and hence \(\Pi ^2\)) are less then \(1\). Thus, </p>
<div class="displaymath" id="a0000000009">
  \begin{align*}  \sum _f w_e w_f |b_e L^{\dagger }b_f ^{\mkern -1.5mu\mathsf{T}}|^2 & = \sum _f \left(\sqrt{w_e w_f} \cdot |b_e L^{\dagger }b_f ^{\mkern -1.5mu\mathsf{T}}|\right)^2 \\ & = \sum _f \Pi (e, f)^2 \\ & = \Pi ^2(e,e) \le 1, \end{align*}
</div>
<p> which was what we were after. </p>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:xelb_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:xelb" style="display: none">
    <a class="latex_link" target="_blank" href="sec-lsolvex.html#lem:xelb">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">4.2</span></div>
    </a>
    <div class="thm_thmcontent"><p> Let \(M^*\) be the routing returned by the algorithm. For any edge \(e\), </p>
<div class="displaymath" id="a0000000046">
  \[  x_e^{(T)} \ge \exp \left( \frac{T}{8\rho } \cdot \textrm{load}_{M^*}(e) \right).  \]
</div>
</div>

  <div class="proof_wrapper" id="a0000000045">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>For any edge \(e\) and \(t \ge 1\), we have </p>
<div class="displaymath" id="a0000000047">
  \begin{align*}  x_e^{(t)} & = \prod _{t' = 1}^t \left( 1 + \frac{1}{2\rho } \cdot \textrm{aload}_{w^{(t')}}(e) \right) \\ & \ge \prod _{t' = 1}^t \left( 1 + \frac{1}{4\rho } \cdot \textrm{load}_{w^{(t')}}(e) \right) \tag *{(by Lemma \ref{lem:ApxSolveLoad})} \\ & \ge \prod _{t' = 1}^t \exp \left( \frac{1}{8\rho } \cdot \textrm{load}_{w^{(t')}}(e) \right) \tag *{(since $e^x \le 1 + 2x$ for $0 {\lt} x {\lt} 1$, and Lemma \ref{lem:WidthBound})} \\ & = \exp \left( \frac{1}{8\rho } \cdot \sum _{t' = 1}^t \textrm{load}_{w^{(t')}}(e) \right) \end{align*}
</div>
<p> In particular, for \(t = T\), we have </p>
<div class="displaymath" id="a0000000048">
  \begin{align*}  x_e^{(T)} & \ge \exp \left( \frac{1}{8\rho } \cdot \sum _{t' = 1}^T \textrm{load}_{w^{(t')}}(e) \right) \\ & \ge \exp \left( \frac{T}{8\rho } \cdot \textrm{load}_{M^*}(e) \right) \tag *{(by convexity of load)} \end{align*}
</div>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="lem:xnormub_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="lem:xnormub" style="display: none">
    <a class="latex_link" target="_blank" href="sec-lsolvex.html#lem:xnormub">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">4.1</span></div>
    </a>
    <div class="thm_thmcontent"><p> For any \(t \ge 1\), \(\|  x^{(t)} \| _1 \le \|  x^{(t-1)} \| _1 \cdot \exp (2 \alpha _{\text{local}}/\rho )\). At the end of the algorithm, \(\|  x^{(T)} \| _1 \le m \cdot \exp (2\alpha _{\text{local}}T/\rho )\). </p>
</div>

  <div class="proof_wrapper" id="a0000000043">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>The implication for \(\|  x^{(T)} \| _1\) follows from the former statement and noting that \(\|  x^{(0)} \| _1 = m\). For any \(t\ge 1\), we have </p>
<div class="displaymath" id="a0000000044">
  \begin{align*}  \|  x^{(t)} \| _1 & = \sum _e x_e^{(t)} = \sum _e x_e^{(t-1)} \cdot \left( 1 + \frac{1}{2\rho } \cdot \textrm{aload}_{w^{(t)}}(e) \right) \\ & = \sum _e x_e^{(t-1)} + \frac{1}{2\rho } \cdot \sum _e x_e^{(t-1)} \cdot \textrm{aload}_{w^{(t)}}(e) \\ & \le \sum _e x_e^{(t-1)} + \frac{\|  x^{(t-1)} \| _1}{\rho } \cdot \sum _e \frac{x_e^{(t-1)}}{\|  x^{(t-1)} \| _1} \cdot \textrm{load}_{w^{(t)}}(e) \tag *{(by Lemma \ref{lem:ApxSolveLoad})} \\ & \le \|  x^{(t-1)} \| _1 + \frac{\|  x^{(t-1)} \| _1}{\rho } \cdot 2 \alpha _{\text{local}}\tag *{(by Lemma \ref{lem:OracleReturn})}\\ & \le \|  x^{(t-1)} \| _1 \cdot \exp \left( \frac{2 \alpha _{\text{local}}}{\rho } \right) \end{align*}
</div>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="thm:CompRatio_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="thm:CompRatio" style="display: none">
    <a class="latex_link" target="_blank" href="sec-lsolvex.html#thm:CompRatio">
    <div class="thm_thmheading">
      <span class="lemma_thmcaption">
      Lemma
      </span>
      <span class="lemma_thmlabel">4.3</span></div>
    </a>
    <div class="thm_thmcontent"><p> The routing returned by the algorithm has competitive ratio \(O(\alpha _{\text{local}})\). </p>
</div>

  <div class="proof_wrapper" id="a0000000049">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▼</span>
      </div>
      <div class="proof_content" style="display: none;">
       <p>Combining Lemmas <a href="sec-lsolvex.html#lem:xnormub">4.1</a> and <a href="sec-lsolvex.html#lem:xelb">4.2</a>, for any edge \(e\), </p>
<div class="displaymath" id="a0000000050">
  \begin{align*}  m \exp \left( \frac{2 \alpha _{\text{local}}T}{\rho } \right) & \ge \|  x^{(T)} \| _1 \ge x_e^{(T)} \ge \exp \left( \frac{T}{8 \rho } \cdot \textrm{load}_{M^*}(e) \right) \end{align*}
</div>
<p>which in particular gives the required upper bound on \(\textrm{load}_{M^*}(e)\) for any edge \(e\), since </p>
<div class="displaymath" id="a0000000051">
  \begin{align*}  \textrm{load}_{M^*}(e) & \le 16 \alpha _{\text{local}}+ \frac{8 \rho \log m}{T} \\ & = O(\alpha _{\text{local}}) \end{align*}
</div>

      </div>
    </div></div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="thm:LapSolve_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="thm:LapSolve" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#thm:LapSolve">
    <div class="thm_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">3.1</span></div>
    </a>
    <div class="thm_thmcontent"><p> There is an algorithm \(\text{ApproxLapSolve}\) that gets as input a Laplacian \(L\) of an \(n\)-vertex \(m\)-edge graph, a vector \(y \in \mathbb {R}^n\), error bound \(\epsilon _L\), and returns a vector \(x \in \mathbb {R}^n\) such that the following holds with probability \(\ge 1 - \frac{1}{poly(n)}\). </p>
<div class="displaymath" id="a0000000014">
  \[  \| x - L^{\dagger }y\| _L \le \epsilon _L\cdot \| L^{\dagger }y\| _L  \]
</div>
<p> where \(\| x\| _L = \sqrt{x^{\mkern -1.5mu\mathsf{T}}L x} \) is the norm induced by the Laplacian. Further, the algorithm runs in time \(\widetilde{O}(m \log (1/\epsilon _L))\). </p>
</div>

  </div>
    
      </div>
    </div>


    
    <div class="dep-modal-container" id="thm:SketchApprox_modal">
      <div class="dep-modal-content">
          <button class="dep-closebtn">
<svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        
  <div class="thm" id="thm:SketchApprox" style="display: none">
    <a class="latex_link" target="_blank" href="sec-apxlsolve.html#thm:SketchApprox">
    <div class="thm_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">3.2</span></div>
    </a>
    <div class="thm_thmcontent"><p> Given \(m \in \mathbb {Z}_{\ge 1}\), \(\delta \in (0,1)\), and \(\epsilon \in (0, 1)\), there is a sketch matrix \(C = \text{SketchMatrix}(m, \delta , \epsilon ) \in \mathbb {R}^{\ell \times m}\) and an algorithm \(\text{RecoverNorm}(s)\) for \(s \in \mathbb {R}^{\ell }\) such that the following properties hold: </p>
<ul class="itemize">
  <li><p>(Approximation) For any \(v \in \mathbb {R}^m\), with probability at least \(1 - \delta \) over the randomness of SketchMatrix, the value of \(r = \text{RecoverNorm}(Cv)\) is </p>
<div class="displaymath" id="a0000000015">
  \[  (1-\epsilon ) \| v\| _1 \le r \le (1+\epsilon ) \| v\| _1  \]
</div>
</li>
  <li><p>\(\ell = c/\epsilon ^2 \cdot \log (1/\delta )\) for some constant \(c{\gt}1\) </p>
</li>
  <li><p>(running time) SketchMatrix and RecoverNorm take time \(O(\ell m)\) and \(poly(\ell )\) respectively. </p>
</li>
</ul>
</div>

  </div>
    
      </div>
    </div>
</div>
</div> <!-- content -->
</div> <!-- wrapper -->
<script src="js/jquery.min.js" type="text/javascript"></script>

<script src="js/d3.min.js"></script>
<script src="js/hpcc.min.js"></script>
<script src="js/d3-graphviz.js"></script>
<script src="js/plastex.js"></script>

<script type="text/javascript">
const graphContainer = d3.select("#graph");
const width = graphContainer.node().clientWidth;
const height = graphContainer.node().clientHeight;


graphContainer.graphviz({useWorker: true})
    .width(width)
    .height(height)
    .fit(true)
    .renderDot(`strict digraph "" {	graph [bgcolor=transparent];	node [label="\N",		penwidth=1.8	];	edge [arrowhead=vee];	"thm:CompRatio"	[color=lightgray,		label=CompRatio,		shape=ellipse,		style=filled];	"lem:MedianApx"	[color=lightgray,		label=MedianApx,		shape=ellipse,		style=filled];	"lem:CombinedApx"	[color=lightgray,		label=CombinedApx,		shape=ellipse,		style=filled];	"lem:MedianApx" -> "lem:CombinedApx";	"thm:SketchApprox"	[color=lightgray,		label=SketchApprox,		shape=ellipse,		style=filled];	"lem:ApxSolveLoad"	[color=lightgray,		label=ApxSolveLoad,		shape=ellipse,		style=filled];	"thm:SketchApprox" -> "lem:ApxSolveLoad";	"lem:xelb"	[color=lightgray,		label=xelb,		shape=ellipse,		style=filled];	"lem:xelb" -> "thm:CompRatio";	"lem:CombinedApx" -> "lem:ApxSolveLoad";	"lem:Localization"	[color=lightgray,		label=Localization,		shape=ellipse,		style=filled];	"lem:OracleReturn"	[color=lightgray,		label=OracleReturn,		shape=ellipse,		style=filled];	"lem:Localization" -> "lem:OracleReturn";	"lem:xnormub"	[color=lightgray,		label=xnormub,		shape=ellipse,		style=filled];	"lem:OracleReturn" -> "lem:xnormub";	"lem:widthHelpfulLemma"	[color=lightgray,		label=widthHelpfulLemma,		shape=ellipse,		style=filled];	"lem:WidthBound"	[color=lightgray,		label=WidthBound,		shape=ellipse,		style=filled];	"lem:widthHelpfulLemma" -> "lem:WidthBound";	"lem:WidthBound" -> "lem:xelb";	"lem:Pi_is_Projection"	[color=lightgray,		label=Pi_is_Projection,		shape=ellipse,		style=filled];	"lem:Pi_is_Projection" -> "lem:widthHelpfulLemma";	"lem:LoadLB"	[color=lightgray,		label=LoadLB,		shape=ellipse,		style=filled];	"lem:LoadLB" -> "lem:ApxSolveLoad";	"lem:InftyLLB"	[color=lightgray,		label=InftyLLB,		shape=ellipse,		style=filled];	"lem:InftyClose"	[color=lightgray,		label=InftyClose,		shape=ellipse,		style=filled];	"lem:InftyLLB" -> "lem:InftyClose";	"lem:InftyLUB"	[color=lightgray,		label=InftyLUB,		shape=ellipse,		style=filled];	"lem:InftyLUB" -> "lem:InftyClose";	"lem:InftyClose" -> "lem:ApxSolveLoad";	"lem:RowtoColumnInfty"	[color=lightgray,		label=RowtoColumnInfty,		shape=ellipse,		style=filled];	"lem:RowtoColumnInfty" -> "lem:ApxSolveLoad";	"lem:ApxSolveLoad" -> "lem:xelb";	"lem:ApxSolveLoad" -> "lem:xnormub";	"thm:LapSolve"	[color=lightgray,		label=LapSolve,		shape=ellipse,		style=filled];	"lem:xnormub" -> "thm:CompRatio";}`)
    .on("end", function () {
        console.log(graphContainer.node().innerHTML);
        interactive();
    });

function interactive() {
  d3.selectAll('.node')
    .attr('pointer-events', 'fill')
    .on('click', function () {
      // Reset the fill color for all nodes and edges to grey
      d3.selectAll('.node').select('ellipse').attr('fill', 'lightgray').attr('stroke', 'lightgray');

      var title = d3.select(this).selectAll('title').text().trim();
      $('#statements > div').hide();
      $('.thm').hide();
      $('#'+title.replace(':', '\\:')+'_modal').show().children().show().children().show();
      $('#statements').show();

      // Find out-neighbors and change the fill of their nodes and edges to blue
      var inNeighborEdges = d3.selectAll('.edge')
        .filter(function(edge) {
          return d3.select(this).select('title').text().split('->')[1].trim() === title;
        });

      var inNeighborNodes = inNeighborEdges.data().map(edge => edge.key.split('->')[0]);
      d3.selectAll('.node')
        .filter(function(node) {
          var nodeTitle = d3.select(this).select('title').text().trim();
          return inNeighborNodes.includes(nodeTitle);
        })
        .select('ellipse')
        .attr('stroke', 'lightblue')
        .attr('fill', 'lightblue');

      // Log information about out-neighbors
      console.log("Inneighbors:", inNeighborNodes);
    });

  d3.selectAll('.dep-closebtn').on('click', function() {
    var modal = d3.select(this).node().parentNode.parentNode.parentNode;
    d3.select(modal).style('display', 'none');
  });
}

window.MathJax = {
  loader: {load: ['[tex]/newcommand']},
  tex: {packages: {'[+]': ['newcommand']}}
};

</script>


</body>
</html>
